{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_textblob(text):\n",
    "    value=TextBlob(text).sentiment.polarity\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_vader(text):\n",
    "    analyser=SentimentIntensityAnalyzer()\n",
    "    positive_value=analyser.polarity_scores(text)['pos']\n",
    "    negative_value=analyser.polarity_scores(text)['neg']\n",
    "    compound_value=analyser.polarity_scores(text)['compound']\n",
    "    neutral_value=analyser.polarity_scores(text)['neu']\n",
    "    return positive_value, negative_value, compound_value, neutral_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_word_selection(text):\n",
    "    word_tokens=word_tokenize(text)\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_words=[w for w in word_tokens if not w in stop_words]\n",
    "#     ps = PorterStemmer()\n",
    "#     stemmed_words=[ps.stem(w) for w in filtered_words]\n",
    "#     total_words=[]\n",
    "#     for i in stemmed_words:\n",
    "#         total_words.append(i)\n",
    "#         for j in filtered_words:\n",
    "#             if j!=i:\n",
    "#                 total_words.append(j)\n",
    "#             else:\n",
    "#                 continue\n",
    "    pos_tagging=nltk.pos_tag(filtered_words)\n",
    "    return pos_tagging\n",
    "#     JJ-Adjective\n",
    "#     NN-Noun\n",
    "#     RB-Adverb\n",
    "#     VB-Verb\n",
    "#     Dictionary contains almost 4.2k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_feature_selection(allword):\n",
    "    relevant_pos_words=[]\n",
    "    for i in pos_tagging:\n",
    "        if (i[1].startswith('NN')==True or i[1].startswith('JJ')==True or i[1].startswith('RB')==True or i[1].startswith('VB')==True):\n",
    "            relevant_pos_words.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return relevant_pos_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_words1(word_list,dictionary_positive,dictionary_negative,dictionary_litigious,dictionary_strongmodal,dictionary_weakmodal,dictionary_constraining,dictionary_uncertainity):\n",
    "    selected_words=[]\n",
    "    for i in word_list:\n",
    "        for j in dictionary_positive:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_negative:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_litigious:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_strongmodal:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_weakmodal:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_constraining:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        for j in dictionary_uncertainity:\n",
    "            if (i[0].upper()==j):\n",
    "                selected_words.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        return selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_positive=pd.read_csv(\"sent_positive.csv\",header=None)\n",
    "dictionary_negative=pd.read_csv(\"sent_negative.csv\",header=None)\n",
    "dictionary_litigious=pd.read_csv(\"sent_litigious.csv\",header=None)\n",
    "dictionary_strongmodal=pd.read_csv(\"sent_strongmodal.csv\",header=None)\n",
    "dictionary_constraining=pd.read_csv(\"sent_constraining.csv\",header=None)\n",
    "dictionary_weakmodal=pd.read_csv(\"sent_weakmodal.csv\",header=None)\n",
    "dictionary_uncertainity=pd.read_csv(\"sent_uncertainity.csv\",header=None)\n",
    "dictionary_master=pd.read_csv(\"master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_words_master(dictionary,word_list):\n",
    "    matched_words=[]\n",
    "    for i in word_list:\n",
    "        for j in dictionary['Word']:\n",
    "            if(i[0].upper()==j):\n",
    "                matched_words.append(i[0])\n",
    "            else:\n",
    "                continue\n",
    "    return matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(word_list):\n",
    "    positive_score=negative_score=compound_score=neutral_score\n",
    "    for i in word_list:\n",
    "        positive_score=predict_sentiment_vader(i)[0]+positive_score\n",
    "        negative_score=predict_sentiment_vader(i)[1]+negative_score\n",
    "        compound_score=predict_sentiment_vader(i)[2]+compound_score\n",
    "        neutral_score=predict_sentiment_vader(i)[3]+neutral_score\n",
    "    return positive_score/len(word_list),negative_score/len(word_list),compound_score/len(word_list),neutral_score/len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
